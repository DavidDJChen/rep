{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About \n",
    "\n",
    "This notebook demonstrates classifiers, which are provided by __Reproducible experiment platform (REP)__ package. <br /> REP contains following classifiers\n",
    "* __scikit-learn__\n",
    "* __TMVA__ \n",
    "* __XGBoost__\n",
    "* __PyBrain__\n",
    "\n",
    "### In this notebook we show the most simple way to\n",
    "* train classifier\n",
    "* build predictions \n",
    "* measure quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy, pandas\n",
    "from rep.utils import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "sig_data = pandas.read_csv('toy_datasets/toyMC_sig_mass.csv', sep='\\t')\n",
    "bck_data = pandas.read_csv('toy_datasets/toyMC_bck_mass.csv', sep='\\t')\n",
    "\n",
    "labels = numpy.array([1] * len(sig_data) + [0] * len(bck_data))\n",
    "data = pandas.concat([sig_data, bck_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First rows of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDF1</th>\n",
       "      <th>CDF2</th>\n",
       "      <th>CDF3</th>\n",
       "      <th>DOCAone</th>\n",
       "      <th>DOCAthree</th>\n",
       "      <th>DOCAtwo</th>\n",
       "      <th>FlightDistance</th>\n",
       "      <th>FlightDistanceError</th>\n",
       "      <th>Hlt1Dec</th>\n",
       "      <th>Hlt2Dec</th>\n",
       "      <th>...</th>\n",
       "      <th>p1_IP</th>\n",
       "      <th>p1_IPSig</th>\n",
       "      <th>p1_Laura_IsoBDT</th>\n",
       "      <th>p1_pt</th>\n",
       "      <th>p2_IP</th>\n",
       "      <th>p2_IPSig</th>\n",
       "      <th>p2_Laura_IsoBDT</th>\n",
       "      <th>p2_pt</th>\n",
       "      <th>peakingbkg</th>\n",
       "      <th>pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 0.111337</td>\n",
       "      <td> 0.012695</td>\n",
       "      <td> 0.123426</td>\n",
       "      <td> 162.650955</td>\n",
       "      <td> 0.870942</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 11.314665</td>\n",
       "      <td> 83.196968</td>\n",
       "      <td>-0.223668</td>\n",
       "      <td> 699.066467</td>\n",
       "      <td> 9.799975</td>\n",
       "      <td> 64.790207</td>\n",
       "      <td>-0.121159</td>\n",
       "      <td> 521.628174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>  220.742111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 0.759755</td>\n",
       "      <td> 0.597375</td>\n",
       "      <td> 0.389256</td>\n",
       "      <td> 0.021781</td>\n",
       "      <td> 0.094551</td>\n",
       "      <td> 0.088421</td>\n",
       "      <td>   4.193265</td>\n",
       "      <td> 1.262280</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0.720070</td>\n",
       "      <td>  7.237868</td>\n",
       "      <td>-0.256142</td>\n",
       "      <td> 587.628935</td>\n",
       "      <td> 0.882111</td>\n",
       "      <td>  8.834325</td>\n",
       "      <td>-0.203220</td>\n",
       "      <td> 532.679950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>  661.208843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 0.796142</td>\n",
       "      <td> 0.566286</td>\n",
       "      <td> 0.011852</td>\n",
       "      <td> 0.004400</td>\n",
       "      <td> 0.009153</td>\n",
       "      <td>   1.580610</td>\n",
       "      <td> 0.261697</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0.362181</td>\n",
       "      <td>  4.173097</td>\n",
       "      <td>-0.252788</td>\n",
       "      <td> 802.746495</td>\n",
       "      <td> 0.427290</td>\n",
       "      <td>  5.008959</td>\n",
       "      <td>-0.409469</td>\n",
       "      <td> 674.122342</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 1290.963982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 0.716397</td>\n",
       "      <td> 0.524712</td>\n",
       "      <td> 0.279033</td>\n",
       "      <td> 0.015171</td>\n",
       "      <td> 0.083900</td>\n",
       "      <td> 0.069127</td>\n",
       "      <td>   7.884569</td>\n",
       "      <td> 1.310151</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0.753449</td>\n",
       "      <td>  6.615949</td>\n",
       "      <td>-0.253550</td>\n",
       "      <td> 564.203857</td>\n",
       "      <td> 0.917409</td>\n",
       "      <td>  8.695459</td>\n",
       "      <td>-0.192284</td>\n",
       "      <td> 537.791687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>  692.654175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 0.996479</td>\n",
       "      <td> 0.888159</td>\n",
       "      <td> 0.005547</td>\n",
       "      <td> 0.070438</td>\n",
       "      <td> 0.064689</td>\n",
       "      <td>  -2.267649</td>\n",
       "      <td> 0.139555</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0.589455</td>\n",
       "      <td> 21.869143</td>\n",
       "      <td>-0.254778</td>\n",
       "      <td> 746.624928</td>\n",
       "      <td> 0.388996</td>\n",
       "      <td>  8.465344</td>\n",
       "      <td>-0.217319</td>\n",
       "      <td> 988.539221</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 1328.837840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CDF1      CDF2      CDF3   DOCAone  DOCAthree   DOCAtwo  \\\n",
       "0  1.000000  1.000000  1.000000  0.111337   0.012695  0.123426   \n",
       "1  0.759755  0.597375  0.389256  0.021781   0.094551  0.088421   \n",
       "2  1.000000  0.796142  0.566286  0.011852   0.004400  0.009153   \n",
       "3  0.716397  0.524712  0.279033  0.015171   0.083900  0.069127   \n",
       "4  1.000000  0.996479  0.888159  0.005547   0.070438  0.064689   \n",
       "\n",
       "   FlightDistance  FlightDistanceError  Hlt1Dec  Hlt2Dec   ...         p1_IP  \\\n",
       "0      162.650955             0.870942        0        0   ...     11.314665   \n",
       "1        4.193265             1.262280        0        0   ...      0.720070   \n",
       "2        1.580610             0.261697        0        0   ...      0.362181   \n",
       "3        7.884569             1.310151        0        0   ...      0.753449   \n",
       "4       -2.267649             0.139555        0        0   ...      0.589455   \n",
       "\n",
       "    p1_IPSig  p1_Laura_IsoBDT       p1_pt     p2_IP   p2_IPSig  \\\n",
       "0  83.196968        -0.223668  699.066467  9.799975  64.790207   \n",
       "1   7.237868        -0.256142  587.628935  0.882111   8.834325   \n",
       "2   4.173097        -0.252788  802.746495  0.427290   5.008959   \n",
       "3   6.615949        -0.253550  564.203857  0.917409   8.695459   \n",
       "4  21.869143        -0.254778  746.624928  0.388996   8.465344   \n",
       "\n",
       "   p2_Laura_IsoBDT       p2_pt  peakingbkg           pt  \n",
       "0        -0.121159  521.628174         NaN   220.742111  \n",
       "1        -0.203220  532.679950         NaN   661.208843  \n",
       "2        -0.409469  674.122342         NaN  1290.963982  \n",
       "3        -0.192284  537.791687         NaN   692.654175  \n",
       "4        -0.217319  988.539221         NaN  1328.837840  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get train and test data\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, train_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers\n",
    "\n",
    "All classifiers inherit from __sklearn.BaseEstimator__ and have the following methods:\n",
    "    \n",
    "* `classifier.fit(X, y, sample_weight=None)` - train classifier\n",
    "        \n",
    "* `classifier.predict_proba(X)` - return probabilities vector for all classes\n",
    "\n",
    "* `classifier.predict(X)` - return predicted labels\n",
    "\n",
    "* `classifier.staged_predict_proba(X)` - return probabilities after each iteration (not supported by TMVA)\n",
    "\n",
    "* `classifier.get_feature_importances()`\n",
    "\n",
    "\n",
    "Here we use `X` to denote matrix with data of shape `[n_samples, n_features]`, `y` is vector with labels (0 or 1) of shape [n_samples], <br /> `sample_weight` is vector with weights.\n",
    "\n",
    "\n",
    "## Difference from default scikit-learn interface\n",
    "X should be* `pandas.DataFrame`, `not numpy.array`. <br />\n",
    "Provided this, you'll be able to choose features used in training by setting e.g. `features=['FlightTime', 'p']` in constructor.\n",
    "\n",
    "\\* it works fine with `numpy.array` as well, but in this case all the features will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variables = [\"FlightDistance\", \"FlightDistanceError\", \"IP\", \"VertexChi2\", \"pt\", \"p0_pt\", \"p1_pt\", \"p2_pt\", 'LifeTime','dira']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn\n",
    "wrapper for scikit-learn classifiers. In this example we use GradientBoosting with default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete\n"
     ]
    }
   ],
   "source": [
    "from rep.estimators import SklearnClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Using gradient boosting with default settings\n",
    "sk = SklearnClassifier(GradientBoostingClassifier(), features=variables)\n",
    "# Training classifier\n",
    "sk.fit(train_data, train_labels)\n",
    "print('training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting probabilities, measuring the quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01925103  0.98074897]\n",
      " [ 0.01577953  0.98422047]\n",
      " [ 0.01379252  0.98620748]\n",
      " ..., \n",
      " [ 0.01624765  0.98375235]\n",
      " [ 0.01442193  0.98557807]\n",
      " [ 0.03089716  0.96910284]]\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities for each class\n",
    "prob = sk.predict_proba(test_data)\n",
    "print prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 0.908278717567\n"
     ]
    }
   ],
   "source": [
    "print 'ROC AUC', roc_auc_score(test_labels, prob[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>effect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FlightDistance</th>\n",
       "      <td> 0.018544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FlightDistanceError</th>\n",
       "      <td> 0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IP</th>\n",
       "      <td> 0.163375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VertexChi2</th>\n",
       "      <td> 0.101842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td> 0.098344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p0_pt</th>\n",
       "      <td> 0.061443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p1_pt</th>\n",
       "      <td> 0.109733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p2_pt</th>\n",
       "      <td> 0.091812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LifeTime</th>\n",
       "      <td> 0.127267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dira</th>\n",
       "      <td> 0.152638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       effect\n",
       "FlightDistance       0.018544\n",
       "FlightDistanceError  0.075000\n",
       "IP                   0.163375\n",
       "VertexChi2           0.101842\n",
       "pt                   0.098344\n",
       "p0_pt                0.061443\n",
       "p1_pt                0.109733\n",
       "p2_pt                0.091812\n",
       "LifeTime             0.127267\n",
       "dira                 0.152638"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk.get_feature_importances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TMVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TMVAClassifier__ wraps classifiers from TMVA (CERN library for machine learning)\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    :param str method: algorithm method (default='kBDT')\n",
    "    :param list(str) | None features: features used in training\n",
    "    :param str factory_options: default=\"!V:!Silent:Color:Transformations=I;D;P;G,D:AnalysisType=Classification\"\n",
    "    :param kwargs: other parameters passed as key=value.\n",
    "\n",
    "TMVA __doesn't__ support `staged_predict_proba`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rep.estimators.tmva import TMVAClassifier, TMVARegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rep.estimators import TMVAClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete\n"
     ]
    }
   ],
   "source": [
    "tmva = TMVAClassifier(method='kBDT', NTrees=50, Shrinkage=0.05, features=variables)\n",
    "tmva.fit(train_data, train_labels)\n",
    "print('training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict probabilities and estimate quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2709105   0.7290895 ]\n",
      " [ 0.28991175  0.71008825]\n",
      " [ 0.17888081  0.82111919]\n",
      " ..., \n",
      " [ 0.27305794  0.72694206]\n",
      " [ 0.22307611  0.77692389]\n",
      " [ 0.31567514  0.68432486]]\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities for each class\n",
    "prob = tmva.predict_proba(test_data)\n",
    "print prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC 0.901148306027\n"
     ]
    }
   ],
   "source": [
    "print 'AUC', roc_auc_score(test_labels, prob[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict labels\n",
    "tmva.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost is open-source library with fast gradient boosting over decision trees.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    :param list(str) features: list of features to train model\n",
    "\n",
    "    :param n_estimators: the number of round for boosting.\n",
    "\n",
    "    :param nthreads: number of parallel threads used to run xgboost.\n",
    "\n",
    "    :param num_feature: feature dimension used in boosting, set to maximum dimension of the feature\n",
    "    (set automatically by xgboost, no need to be set by user).\n",
    "\n",
    "    :param gamma: minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
    "     The larger, the more conservative the algorithm will be.\n",
    "\n",
    "    :param eta: step size shrinkage used in update to prevents overfitting.\n",
    "    After each boosting step, we can directly get the weights of new features\n",
    "     and eta actually shrinkage the feature weights to make the boosting process more conservative.\n",
    "\n",
    "    :param max_depth: maximum depth of a tree.\n",
    "\n",
    "    :params scale_pos_weight: ration of weights of the class 1 to the weights of the class 0.\n",
    "\n",
    "    :param min_child_weight: minimum sum of instance weight(hessian) needed in a child.\n",
    "    If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight,\n",
    "    then the building process will give up further partitioning.\n",
    "    In linear regression mode, this simply corresponds to minimum number of instances needed to be in each node.\n",
    "    The larger, the more conservative the algorithm will be.\n",
    "\n",
    "    :param subsample: subsample ratio of the training instance.\n",
    "    Setting it to 0.5 means that XGBoost randomly collected half of the data instances to grow trees\n",
    "        and this will prevent overfitting.\n",
    "\n",
    "    :param colsample: subsample ratio of columns when constructing each tree.\n",
    "\n",
    "    :param objective: specify the learning task and the corresponding learning objective, and the options are below:\n",
    "    \"reg:linear\" --linear regression\n",
    "    \"reg:logistic\" --logistic regression\n",
    "    \"binary:logistic\" --logistic regression for binary classification, output probability\n",
    "    \"binary:logitraw\" --logistic regression for binary classification, output score before logistic transformation\n",
    "    \"multi:softmax\" --set XGBoost to do multiclass classification using the softmax objective, you also need to\n",
    "        set num_class(number of classes)\n",
    "    \"multi:softprob\" --same as softmax, but output a vector of ndata * nclass, which can be further reshaped to ndata,\n",
    "        nclass matrix. The result contains predicted probability of each data point belonging to each class.\n",
    "    \"rank:pairwise\" --set XGBoost to do ranking task by minimizing the pairwise loss\n",
    "\n",
    "    :param base_score: the initial prediction score of all instances, global bias.\n",
    "\n",
    "    :param random_state: random number seed.\n",
    "\n",
    "    :param verbose: if 1, will print messages during training\n",
    "\n",
    "    :param missing: the number considered by xgboost as missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antares/code/xgboost/wrapper/xgboost.py:80: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  if label != None:\n",
      "/Users/antares/code/xgboost/wrapper/xgboost.py:82: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  if weight !=None:\n"
     ]
    }
   ],
   "source": [
    "from rep.estimators import XGBoostClassifier\n",
    "# XGBoost with default parameters\n",
    "xgb = XGBoostClassifier(features=variables)\n",
    "xgb.fit(train_data, train_labels, sample_weight=numpy.ones(len(train_labels)))\n",
    "print('training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict probabilities and estimate quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.922402718668\n"
     ]
    }
   ],
   "source": [
    "prob = xgb.predict_proba(test_data)\n",
    "print 'ROC AUC:', roc_auc_score(test_labels, prob[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>effect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FlightDistance</th>\n",
       "      <td> 1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FlightDistanceError</th>\n",
       "      <td>  940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IP</th>\n",
       "      <td>  934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VertexChi2</th>\n",
       "      <td>  918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>  998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p0_pt</th>\n",
       "      <td>  866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p1_pt</th>\n",
       "      <td> 1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p2_pt</th>\n",
       "      <td> 1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LifeTime</th>\n",
       "      <td>  414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dira</th>\n",
       "      <td>  338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     effect\n",
       "FlightDistance         1012\n",
       "FlightDistanceError     940\n",
       "IP                      934\n",
       "VertexChi2              918\n",
       "pt                      998\n",
       "p0_pt                   866\n",
       "p1_pt                  1070\n",
       "p2_pt                  1040\n",
       "LifeTime                414\n",
       "dira                    338"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.get_feature_importances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advantages of common interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see above, all the classifiers implement the same interface, \n",
    "this simplifies work, simplifies comparison of different classifiers, \n",
    "but this is not the only profit. \n",
    "\n",
    "`Sklearn` provides different tools to combine different classifiers and transformers. \n",
    "One of this tools is `AdaBoost`, which is abstract metaclassifier built on the top of some other classifier (usually, decision dree)\n",
    "\n",
    "Let's show that now you can run AdaBoost over classifiers from other libraries! <br />\n",
    "_(isn't boosting over neural network what you were dreaming of all your life?)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost over TMVA classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Construct AdaBoost with TMVA as base estimator\n",
    "base_tmva = TMVAClassifier(method='kBDT', NTrees=15, Shrinkage=0.05)\n",
    "ada_tmva  = SklearnClassifier(AdaBoostClassifier(base_estimator=base_tmva, n_estimators=5), features=variables)\n",
    "ada_tmva.fit(train_data, train_labels)\n",
    "print('training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC 0.885266565878\n"
     ]
    }
   ],
   "source": [
    "prob = ada_tmva.predict_proba(test_data)\n",
    "print 'AUC', roc_auc_score(test_labels, prob[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost over XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete!\n"
     ]
    }
   ],
   "source": [
    "# Construct AdaBoost with xgboost base estimator\n",
    "base_xgb = XGBoostClassifier(n_estimators=50)\n",
    "# ada_xgb = SklearnClassifier(AdaBoostClassifier(base_estimator=base_xgb, n_estimators=1), features=variables)\n",
    "ada_xgb = AdaBoostClassifier(base_estimator=base_xgb, n_estimators=1)\n",
    "ada_xgb.fit(train_data[variables], train_labels)\n",
    "print('training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC 0.917898066693\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities for each class\n",
    "prob = ada_xgb.predict_proba(test_data[variables])\n",
    "print 'AUC', roc_auc_score(test_labels, prob[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC 0.950702225833\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities for each class\n",
    "prob = ada_xgb.predict_proba(train_data[variables])\n",
    "print 'AUC', roc_auc_score(train_labels, prob[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyBrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__PyBrainClassifier__ wraps classifiers from PyBrain. \n",
    "PyBrain is short for __Py__thon-__B__ased __R__einforcement Learning, __A__rtificial __I__ntelligence and __N__eural Network Library.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    :param features: features used in training.\n",
    "    :type features: list[str] or None\n",
    "    :param iters: number of iterations of training.\n",
    "\n",
    "    net parameters:\n",
    "    :param list layers: indicate how many neurons in each hidden(!) layer; default is 1 layer included 10 neurons.\n",
    "    :param hiddenclass: classes of the hidden layers; default is 'SigmoidLayer'\n",
    "    :type hiddenclass: list of str\n",
    "    :param params: other net parameters:\n",
    "        :param boolean bias and outputbias: flags to indicate whether the network should have the corresponding biases;\n",
    "         both default to True.\n",
    "        :param boolean peepholes\n",
    "        :param boolean recurrent: if the `recurrent` flag is set, a :class:`RecurrentNetwork` will be created,\n",
    "         otherwise a :class:`FeedForwardNetwork`.\n",
    "    :type params: dict\n",
    "\n",
    "    trainer parameters:\n",
    "    :param float learningrate: gives the ratio of which parameters are changed into the direction of the gradient.\n",
    "    :param float lrdecay: the learning rate decreases by lrdecay, which is used to to multiply the learning rate after each training step.\n",
    "    :param float momentum: the ratio by which the gradient of the last timestep is used.\n",
    "    :param boolean verbose: if you want trainer to print all the actions - set it. Default is False.\n",
    "    :param boolean batchlearning: if batchlearning is set, the parameters are updated only at the end of each epoch.   Default is False.\n",
    "    :param float weightdecay: corresponds to the weightdecay rate, where 0 is no weight decay at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rep.utils import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "sig_data = pandas.read_csv('toy_datasets/toyMC_sig_mass.csv', sep='\\t')\n",
    "bck_data = pandas.read_csv('toy_datasets/toyMC_bck_mass.csv', sep='\\t')\n",
    "\n",
    "labels = numpy.array([1] * len(sig_data) + [0] * len(bck_data))\n",
    "data = pandas.concat([sig_data, bck_data])\n",
    "variables = [\"FlightDistance\", \"FlightDistanceError\", \"IP\", \"VertexChi2\", \"pt\", \"p0_pt\", \"p1_pt\", \"p2_pt\", 'LifeTime','dira']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Split on train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72449, 10) (72450, 10) 72449 72450\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[variables].values, labels, train_size=0.5, random_state = 384)\n",
    "print X_train.shape, X_test.shape, len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Now we make a classifier with 2 hidden layers with 10 and 20 neurons in each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rep.estimators import PyBrainClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Binarizer\n",
    "\n",
    "pb = PyBrainClassifier(layers=[10, 20], epochs=10, verbose=True, scaler=StandardScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error:  0.040186239795\n",
      "Total error:  0.0368244026758\n",
      "Total error:  0.0364056124783\n",
      "Total error:  0.0361849120992\n",
      "Total error:  0.0359050794801\n",
      "Total error:  0.0358441554205\n",
      "Total error:  0.0357131273455\n",
      "Total error:  0.0357788689297\n",
      "Total error:  0.0357235802459\n",
      "Total error:  0.035619950252\n",
      "CPU times: user 10min 42s, sys: 2.26 s, total: 10min 44s\n",
      "Wall time: 10min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyBrainClassifier(batchlearning=False, delta0=0.1, deltamax=0.5,\n",
       "         deltamin=1e-06, epochs=10, etaminus=0.5, etaplus=1.2,\n",
       "         features=['Feature_0', 'Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5', 'Feature_6', 'Feature_7', 'Feature_8', 'Feature_9'],\n",
       "         hiddenclass=['SigmoidLayer', 'SigmoidLayer'], layers=[10, 20],\n",
       "         learningrate=0.01, lrdecay=1.0, momentum=0.0,\n",
       "         scaler=StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "         use_rprop=False, verbose=True, weightdecay=0.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Predicting probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01786076,  0.98213924],\n",
       "       [ 0.09110269,  0.90889731],\n",
       "       [ 0.22386682,  0.77613318],\n",
       "       ..., \n",
       "       [ 0.39654057,  0.60345943],\n",
       "       [ 0.02806454,  0.97193546],\n",
       "       [ 0.02478111,  0.97521889]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = pb.predict_proba(X_test)\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Predicting result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = pb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0975569358178\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.74      0.58      6611\n",
      "          1       0.97      0.92      0.94     65839\n",
      "\n",
      "avg / total       0.93      0.90      0.91     72450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print \"Accuracy:\", zero_one_loss(y_pred, y_test)\n",
    "print \"Classification report:\"\n",
    "print classification_report(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other advantages of common interface\n",
    "There are many things you can do with classifiers now: \n",
    "* cloning\n",
    "* getting / setting parameters as dictionaries \n",
    "* do automatic hyperparameter optimization \n",
    "* build pipelines (`sklearn.pipeline`)\n",
    "* use hierarchical training, training on subsets\n",
    "* passing over internet / train classifiers on other machines\n",
    "\n",
    "And you can replace classifiers at any moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "### Exercise 1. Play with parameters in each type of classifiers\n",
    "\n",
    "### Exercise 2. Add weight column and train models with weights in training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
